{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preproc(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Only look at white parts\n",
    "    _,bwimg=cv2.threshold(gray,240,255,cv2.THRESH_BINARY)\n",
    "    return bwimg\n",
    "\n",
    "def get_chars(img):\n",
    "    \"\"\"Break an image of numbers into a list of images of characters\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/50713023/license-plate-character-segmentation-python-opencv\n",
    "    \"\"\"\n",
    "    chars=[]\n",
    "    _,contours,_=cv2.findContours(img, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    # Sort bounding boxes from left to right\n",
    "    contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    for ctr in contours:\n",
    "        # Get bounding box\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "        # Getting ROI\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        chars.append(roi)\n",
    "    return chars\n",
    "\n",
    "def filter_chars(img):\n",
    "    \"\"\"Filter out non-character glyphs based on height/width ratio\n",
    "    \"\"\"\n",
    "    h,w=img.shape\n",
    "    ratio=h/w\n",
    "    if ratio<=1 or ratio>2.1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def conform_size(img):\n",
    "    \"\"\"Resize images to conform to the size of MNIST images, which is 28x28\n",
    "    \"\"\"\n",
    "    target_width=20\n",
    "    target_height=20\n",
    "    padding_second=4\n",
    "    h,w=img.shape\n",
    "    if w>h:\n",
    "        # Resize without stretching\n",
    "        new_h=int(np.round(h*target_height/w))\n",
    "        resized_img = cv2.resize(img, (target_width, new_h))\n",
    "        # Pad image\n",
    "        blank=target_height-new_h\n",
    "        pad_t=int(np.floor(blank/2))\n",
    "        pad_b=int(np.floor((blank+1)/2))\n",
    "        padded_img=cv2.copyMakeBorder(resized_img,pad_t,pad_b,0,0,cv2.BORDER_CONSTANT,value=0)\n",
    "        # Do padding again to add blanks so that the image resembles those from MNIST\n",
    "        # Otherwise the trained model is destined to fail\n",
    "        padded_img2=cv2.copyMakeBorder(padded_img,padding_second,padding_second,padding_second,padding_second,cv2.BORDER_CONSTANT,value=0)\n",
    "    else:\n",
    "        new_w=int(np.round(w*target_width/h))\n",
    "        resized_img = cv2.resize(img, (new_w,target_height))\n",
    "        blank=target_width-new_w\n",
    "        pad_l=int(np.floor(blank/2))\n",
    "        pad_r=int(np.floor((blank+1)/2))\n",
    "        padded_img=cv2.copyMakeBorder(resized_img,0,0,pad_l,pad_r,cv2.BORDER_CONSTANT,value=0)\n",
    "        padded_img2=cv2.copyMakeBorder(padded_img,padding_second,padding_second,padding_second,padding_second,cv2.BORDER_CONSTANT,value=0)\n",
    "    # 0-255 to 0-1\n",
    "    normalized=padded_img2/255\n",
    "    normalized = normalized.reshape(28, 28, 1)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_imgs=glob.glob(\"training/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=[]\n",
    "train_y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in path_train_imgs:\n",
    "    label=os.path.basename(path).split(\".\")[0]\n",
    "    labels=[int(x) for x in list(label)]\n",
    "    img_orig=cv2.imread(path)\n",
    "    img=img_preproc(img_orig)\n",
    "    characters=get_chars(img)\n",
    "    filt_chars=[img for img in characters if filter_chars(img)]\n",
    "    # \"Normalized\" characters\n",
    "    norm_chars=[conform_size(char) for char in filt_chars]\n",
    "    train_x=train_x+norm_chars\n",
    "    train_y=train_y+labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=np.array(train_y)\n",
    "train_x=np.array(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pkl\",\"wb\") as f:\n",
    "    pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=== Data generation ends here ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(path_train_imgs):\n",
    "    char=train_x[i,:,:,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
